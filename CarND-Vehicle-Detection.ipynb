{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarND-Vehicle-Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "* Note: for those first two steps donâ€™t forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "data_folder_ids = [1,2]\n",
    "data_folder=\"../DataSets/data1/\"\n",
    "model_file = \"./model.p\"\n",
    "scaler_file=\"./scaler.p\"\n",
    "\n",
    "RESIZE_H = 64\n",
    "RESIZE_W = 64\n",
    "RESIZE_TUPLE = (RESIZE_W, RESIZE_H)\n",
    "SPATIAL_SIZE = (32, 32)\n",
    "BINS_RANGE = (0, 255)\n",
    "HIST_BINS = 32\n",
    "ORIENT = 8\n",
    "PIXELS_PER_CELL = 8\n",
    "CELL_PER_BLOCK = 2\n",
    "DEFAULT_COLOR_SPACE = 'YCrCb'\n",
    "TIME_WINDOW = 20\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_files = glob.glob(data_folder + 'vehicles/**/*.png', recursive=True)\n",
    "non_vehicle_files = glob.glob(data_folder + 'non-vehicles/**/*.png', recursive=True)\n",
    "print('Total Vehicle files : {}'.format(len(vehicle_files)))\n",
    "print('Total non Vehicle files : {}'.format(len(non_vehicle_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_hog_features(image, orient=ORIENT, pix_per_cell=PIXELS_PER_CELL, cell_per_block=CELL_PER_BLOCK, vis=False,\n",
    "feature_vec=True):\n",
    "    if vis:\n",
    "        features, hog_image = hog(image, orientations=orient,\n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                  transform_sqrt=True,\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        features = hog(image, orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=True,\n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "def bin_spatial(image, size=SPATIAL_SIZE):\n",
    "    features = cv2.resize(image, size).ravel()\n",
    "    return features\n",
    "\n",
    "def color_hist(image, nbins=HIST_BINS, bins_range=BINS_RANGE):\n",
    "    channel1_hist = np.histogram(image[:, :, 0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(image[:, :, 1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(image[:, :, 2], bins=nbins, range=bins_range)\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features\n",
    "\n",
    "def extract_features_from_image(image, color_space=DEFAULT_COLOR_SPACE, spatial_size=SPATIAL_SIZE, hist_bins=HIST_BINS,\n",
    "                                orient=ORIENT, pix_per_cell=PIXELS_PER_CELL,\n",
    "                                cell_per_block=CELL_PER_BLOCK, hog_channel='ALL', spatial_feat=True,\n",
    "                                hist_feat=True, hog_feat=True):\n",
    "    image_features = []\n",
    "\n",
    "    feature_image = convert_color(np.copy(image), 'HSV')\n",
    "    feature_image[:, :, 2] += np.random.randint(0, 50)\n",
    "    feature_image = cv2.cvtColor(feature_image, cv2.COLOR_HSV2BGR)\n",
    "    feature_image = convert_color(np.copy(image), color_space)\n",
    "\n",
    "    if spatial_feat:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        image_features.append(spatial_features)\n",
    "\n",
    "    if hist_feat:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        image_features.append(hist_features)\n",
    "\n",
    "    if hog_feat:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(extract_hog_features(feature_image[:, :, channel],\n",
    "                                                     orient, pix_per_cell, cell_per_block,\n",
    "                                                     vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)\n",
    "        else:\n",
    "            hog_features = extract_hog_features(feature_image[:, :, hog_channel], orient,\n",
    "                                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        image_features.append(hog_features)\n",
    "\n",
    "    return np.concatenate(image_features)\n",
    "\n",
    "def extract_features_from_file_list(file_list):\n",
    "    features = []\n",
    "    for image_file in tqdm(file_list):\n",
    "        resize_h, resize_w = 64, 64\n",
    "        image = cv2.resize(cv2.imread(image_file), (resize_w, resize_h))\n",
    "        file_features = extract_features_from_image(image)\n",
    "        features.append(file_features)\n",
    "    return features\n",
    "\n",
    "def convert_color(image, dest_color_space=DEFAULT_COLOR_SPACE):\n",
    "    if dest_color_space == 'YCrCb':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    elif dest_color_space == 'YUV':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    elif dest_color_space == 'LUV':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif dest_color_space == 'HLS':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    elif dest_color_space == 'HSV':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif dest_color_space == 'grayscale':\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return image\n",
    "\n",
    "class HOGClassifier:\n",
    "    def __init__(self):\n",
    "        self.svc = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.X_scaler = None\n",
    "\n",
    "    def train(self, vehicle_files, non_vehicle_files, test_size=0.2):\n",
    "        vehicle_features = extract_features_from_file_list(vehicle_files)\n",
    "        non_vehicle_features = extract_features_from_file_list(non_vehicle_files)\n",
    "        X = np.vstack((vehicle_features, non_vehicle_features)).astype(np.float64)\n",
    "        X_scaler = StandardScaler().fit(X)\n",
    "        scaled_X = X_scaler.transform(X)\n",
    "        y = np.hstack((np.ones(len(vehicle_features)), np.zeros(len(non_vehicle_features))))\n",
    "        rand_state = np.random.randint(0, 100)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=test_size, random_state=rand_state)\n",
    "        svc = LinearSVC()\n",
    "        svc.fit(X_train, y_train)\n",
    "        print(\"Training complete\")\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.X_scaler = X_scaler\n",
    "        self.svc = svc\n",
    "        return svc\n",
    "\n",
    "    def test(self, n_predict=15):\n",
    "        print('Accuracy:     ', round(self.svc.score(self.X_test, self.y_test), 4))\n",
    "        print('SVC Predicts: ', self.svc.predict(self.X_test[0:n_predict]))\n",
    "        print('Labels:       ', self.y_test[0:n_predict])\n",
    "\n",
    "    def dump(self, model_path, scaler_path):\n",
    "        pickle.dump(self.svc, open(model_path, \"wb\"))\n",
    "        pickle.dump(self.X_scaler, open(scaler_path, \"wb\"))\n",
    "        print(\"End dump\")\n",
    "\n",
    "    def get(self, model_path, scaler_path):\n",
    "        svc_trained = pickle.load(open(model_path, \"rb\"))\n",
    "        xscaler = pickle.load(open(scaler_path, \"rb\"))\n",
    "        return svc_trained, xscaler\n",
    "\n",
    "classifier = HOGClassifier()\n",
    "classifier.train(vehicle_files, non_vehicle_files)\n",
    "classifier.test(n_predict=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.dump(model_file, scaler_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_trained, xscaler = classifier.get(model_file, scaler_file)\n",
    "hot_windows_history = collections.deque(maxlen=TIME_WINDOW)\n",
    "\n",
    "def normalize_image(image):\n",
    "    image = np.float32(image)\n",
    "    image = image / image.max() * 255\n",
    "    return np.uint8(image)\n",
    "\n",
    "def gaussian_blur(image, kernel_size=5):\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def draw_labeled_bounding_boxes(image, labeled_frame, num_objects):\n",
    "    for car_number in range(1, num_objects + 1):\n",
    "        rows, cols = np.where(labeled_frame == car_number)\n",
    "        x_min, y_min = np.min(cols), np.min(rows)\n",
    "        x_max, y_max = np.max(cols), np.max(rows)\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color=(255, 0, 0), thickness=6)\n",
    "    return image\n",
    "\n",
    "def draw_boxes(image, bbox_list, color=(0, 0, 255), thick=6):\n",
    "    img_copy = np.copy(image)\n",
    "    for bbox in bbox_list:\n",
    "        tl_corner = tuple(bbox[0])\n",
    "        br_corner = tuple(bbox[1])\n",
    "        cv2.rectangle(img_copy, tl_corner, br_corner, color, thick)\n",
    "    return img_copy\n",
    "\n",
    "def compute_heatmap_from_detections(frame, hot_windows, threshold=5, verbose=False):\n",
    "    h, w, c = frame.shape\n",
    "\n",
    "    heatmap = np.zeros(shape=(h, w), dtype=np.uint8)\n",
    "\n",
    "    for bbox in hot_windows:\n",
    "        # for each bounding box, add heat to the corresponding rectangle in the image\n",
    "        x_min, y_min = bbox[0]\n",
    "        x_max, y_max = bbox[1]\n",
    "        heatmap[y_min:y_max, x_min:x_max] += 1  # add heat\n",
    "\n",
    "    # apply threshold + morphological closure to remove noise\n",
    "    _, heatmap_thresh = cv2.threshold(heatmap, threshold, 255, type=cv2.THRESH_BINARY)\n",
    "    heatmap_thresh = cv2.morphologyEx(heatmap_thresh, op=cv2.MORPH_CLOSE,\n",
    "                                      kernel=cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 13)), iterations=1)\n",
    "    if verbose:\n",
    "        f, ax = plt.subplots(1, 3)\n",
    "        ax[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        ax[1].imshow(heatmap, cmap='hot')\n",
    "        ax[2].imshow(heatmap_thresh, cmap='hot')\n",
    "        plt.show()\n",
    "\n",
    "    return heatmap, heatmap_thresh\n",
    "\n",
    "def search_vehicles(image, y_start, y_stop, scale, svc, feature_scaler, color_space=DEFAULT_COLOR_SPACE,\n",
    "                  spatial_size=SPATIAL_SIZE, hist_bins=HIST_BINS, orient=ORIENT, pix_per_cell=PIXELS_PER_CELL,\n",
    "                  cell_per_block=CELL_PER_BLOCK):\n",
    "    hot_windows = []\n",
    "    resize_h = RESIZE_H\n",
    "    resize_w = RESIZE_W\n",
    "    draw_img = np.copy(image)\n",
    "    image_crop = draw_img[y_start:y_stop, :, :]\n",
    "    image_crop = convert_color(image_crop, dest_color_space=color_space)\n",
    "\n",
    "    if scale != 1:\n",
    "        imshape = image_crop.shape\n",
    "        image_crop = cv2.resize(image_crop, (np.int(imshape[1] / scale), np.int(imshape[0] / scale)))\n",
    "\n",
    "    ch1 = image_crop[:, :, 0]\n",
    "    ch2 = image_crop[:, :, 1]\n",
    "    ch3 = image_crop[:, :, 2]\n",
    "    n_x_blocks = (ch1.shape[1] // pix_per_cell) - 1\n",
    "    n_y_blocks = (ch1.shape[0] // pix_per_cell) - 1\n",
    "\n",
    "    window = 64\n",
    "    n_blocks_per_window = (window // pix_per_cell) - 1\n",
    "    cells_per_step = 4\n",
    "    n_x_steps = (n_x_blocks - n_blocks_per_window) // cells_per_step\n",
    "    n_y_steps = (n_y_blocks - n_blocks_per_window) // cells_per_step\n",
    "    hog1 = extract_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = extract_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = extract_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "    for xb in range(n_x_steps):\n",
    "        for yb in range(n_y_steps):\n",
    "            y_pos = yb * cells_per_step\n",
    "            x_pos = xb * cells_per_step\n",
    "            hog_feat1 = hog1[y_pos:y_pos + n_blocks_per_window, x_pos:x_pos + n_blocks_per_window].ravel()\n",
    "            hog_feat2 = hog2[y_pos:y_pos + n_blocks_per_window, x_pos:x_pos + n_blocks_per_window].ravel()\n",
    "            hog_feat3 = hog3[y_pos:y_pos + n_blocks_per_window, x_pos:x_pos + n_blocks_per_window].ravel()\n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "            x_left = x_pos * pix_per_cell\n",
    "            y_top = y_pos * pix_per_cell\n",
    "            subimg = cv2.resize(image_crop[y_top:y_top + window, x_left:x_left + window], (resize_w, resize_h))\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "            test_features = feature_scaler.transform(\n",
    "                np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "            test_prediction = svc.decision_function(test_features)\n",
    "\n",
    "            if test_prediction > 0.2 and test_prediction <= 1:\n",
    "                xbox_left = np.int(x_left * scale)\n",
    "                ytop_draw = np.int(y_top * scale)\n",
    "                win_draw = np.int(window * scale)\n",
    "                tl_corner_draw = (xbox_left, ytop_draw + y_start)\n",
    "                br_corner_draw = (xbox_left + win_draw, ytop_draw + win_draw + y_start)\n",
    "                cv2.rectangle(draw_img, tl_corner_draw, br_corner_draw, (0, 0, 255), 6)\n",
    "                hot_windows.append((tl_corner_draw, br_corner_draw))\n",
    "\n",
    "    return hot_windows\n",
    "\n",
    "def process_image(frame, svc=None, scaler=None, keep_state=True, verbose=False):\n",
    "    hot_windows = []\n",
    "\n",
    "    if verbose is False:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    frame_blurred = gaussian_blur(frame, 3)\n",
    "\n",
    "    for size_subsample in np.arange(1, 4, .3):\n",
    "        hot_windows += search_vehicles(frame_blurred, 400, 600, size_subsample, svc, scaler)\n",
    "\n",
    "    if keep_state:\n",
    "        if hot_windows:\n",
    "            hot_windows_history.append(hot_windows)\n",
    "            hot_windows = np.concatenate(hot_windows_history)\n",
    "\n",
    "    thresh = TIME_WINDOW if keep_state else 1\n",
    "    heatmap, heatmap_thresh = compute_heatmap_from_detections(frame, hot_windows, threshold=thresh, verbose=False)\n",
    "\n",
    "    img_thresh = np.zeros(heatmap_thresh.shape, dtype=np.uint8)\n",
    "    img_blur = gaussian_blur(heatmap_thresh, 21)\n",
    "    img_thresh[img_blur > 50] = 255\n",
    "\n",
    "    img_hot_windows = draw_boxes(frame, hot_windows, color=(0, 0, 255), thick=2)\n",
    "    img_heatmap = cv2.applyColorMap(normalize_image(heatmap), colormap=cv2.COLORMAP_HOT)\n",
    "    img_labeling = normalize_image(img_thresh)\n",
    "    _, contours, _ = cv2.findContours(img_thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    boxes = []\n",
    "    for i, contour in enumerate(contours):\n",
    "        rectangle = cv2.boundingRect(contour)\n",
    "        x, y, w, h = rectangle\n",
    "        boxes.append([(x, y), (x + w, y + h)])\n",
    "\n",
    "    img_detection = draw_boxes(frame, boxes, thick=2, color=(255, 0, 0))\n",
    "    return cv2.cvtColor(img_detection, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def process_video(input_file=\"project_video.mp4\", output_file='output_video.mp4', svc=None, scaler=None,\n",
    "                   keep_state=True, verbose=False):\n",
    "    clip1 = VideoFileClip(input_file)\n",
    "\n",
    "    def _process_image(frame, svc=svc, scaler=scaler, keep_state=keep_state, verbose=verbose):\n",
    "        return process_image(frame, svc=svc, scaler=scaler, keep_state=keep_state, verbose=verbose)\n",
    "\n",
    "    out_clip = clip1.fl_image(_process_image)\n",
    "    return out_clip.write_videofile(output_file, audio=False, verbose=True, progress_bar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time process_video(svc=svc_trained, scaler=xscaler, keep_state=True, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
